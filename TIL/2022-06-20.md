머신러닝 변수에 이것저것 생각하다가 오히려 예측 결과 정확도가 떨어지는 경우도 많다.
소음이 들어가는 경우가 많기 때문이다.

pd.get_dummies() -> 판다스에서 지원하는 One-Hot-Encoding을 위한 메서드

cross validate

테스트 값들 cv마다 보여주기

from sklearn.model_selection import cross_validate

cross_validate(model, X_train, y_train, cv=5)

테스트 스코어만 보여주기

from sklearn.model_selection import cross_val_score

cross_val_score(model, X_train, y_train, cv=5)

o 불순도 확인 
 - 트리계열 알고리즘은 불순도를 낮추는 방향으로 진행
 - 지니계수 또는 엔트로피가 0이 되면 분류를 멈춤
 - 지니계수는 CART 알고리즘, 엔트로피는 ID3 알고리즘 

o Feature 엔지니어링
 - (목적) 모델 정확도 향상
 - (내용) 주어진 데이터를 예측 모델의 문제를 잘 표현할 수 있는 features로 변형시키는 과정
 - (종류) Encoding, Normalization, imputation, Outliers, Scaling

o One-Hot-Encoding
 - 범주형 변수를 수치형 변수로 나타내는 방법

o 랜덤포레스트

어떤게 신호이고, 어떤게 소음인지를 잘 찾아내야 한다.
오류 발생 시 확인할 것.
결측치 확인, 문자열 확인하기.

엔트로피 - 0이면 가장 확실, 1이면 가장 불확실하다.
지니 = 0이면 불순도가 없다. 0.5이면 불순도가 많다. 확률이 반반이면
생존하는지 안하는지를 알 수가 없으니까.

imputation = 결측치를 임의수로 채워넣는것.

normalization - 너무 왼쪽이나, 오른쪽으로 치우치지 않게, 너무 위로 뾰족하지 않게 설정.

one-hot-encoding : 값에 해당하는 것만 True값을 반영.

pd.get_dummies() : 희소행렬이 많이 생김. 존재하는 값이 별로 없음.

피쳐엔지니어링은 모델이 잘 학습할 수 있도록 데이터를 전처리하는 과정.

1. Random Forest : Decision Tree를 여러 개 앙상블한 것 
        - 따라서 거의 유사하지만, 트리의 개수를 설정하는 n_estimators 가 존재함
2. Decision Tree : 불순도를 평가하는 방법에는 지니계수 / 엔트로피가 있음
        - 지니계수와 달리 엔트로피는 log2를 사용
        - 엔트로피 = -(p1log2(p1) + p2log2(p2))  * p1 + p2 = 1
3. 당뇨병, 이번 예시처럼 test data에 label_data가 없는 경우에는 교차검증, Cross validation을 사용할 수 있음
        - 관련 모듈에는 cross_validate / cross_val_predict / cross_val_score가 있는데 필요에 따라 사용
4. 모델 학습이나 교차검증 등을 할 때, 문자 데이터나 결측치가 있으면 안 됨!
        - feature engineering의 한 방법으로 one-hot-encoding이 있음!
        - 단순히 문자를 숫자로 바꿔주면 Ordinal encoding이 되어 불필요한 관계가 생길 수 있는데, 이 때 좋음
